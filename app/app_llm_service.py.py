#!/usr/bin/env python3
"""
Servi√ßo para integra√ß√£o com LLM local (Ollama)
"""

import httpx
import json
import logging
from typing import Dict, Any, Optional
import asyncio

logger = logging.getLogger(__name__)

class LLMService:
    """Servi√ßo para comunica√ß√£o com Ollama"""
    
    def __init__(self, ollama_url: str = "http://localhost:11434", model: str = "gemma2:2b"):
        self.ollama_url = ollama_url
        self.model = model
        self.client = httpx.AsyncClient(timeout=30.0)
        
        # Template do prompt profissional
        self.system_prompt = """Voc√™ √© um analista SOC especialista em seguran√ßa cibern√©tica.
Dado um log de alerta do IDS Suricata, voc√™ deve analisar e responder APENAS em formato JSON v√°lido.

Sua resposta deve seguir exatamente este formato:
{
  "resumo": "Descri√ß√£o concisa do evento em at√© 2 linhas",
  "tipo_ataque": "Tipo espec√≠fico do ataque (ex: port_scan, brute_force, sql_injection, etc)",
  "criticidade": "baixa, m√©dia ou alta",
  "acao_recomendada": "A√ß√£o pr√°tica espec√≠fica para o SOC"
}

IMPORTANTE: Responda APENAS com o JSON, sem texto adicional."""

    async def check_ollama_health(self) -> bool:
        """Verificar se Ollama est√° rodando"""
        try:
            response = await self.client.get(f"{self.ollama_url}/api/tags")
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Ollama health check failed: {e}")
            return False

    async def analyze_log(self, log_data: Dict[Any, Any]) -> Optional[Dict[str, str]]:
        """
        Analisar log com LLM
        """
        try:
            # Preparar contexto do log
            log_context = self._prepare_log_context(log_data)
            
            # Prompt completo
            full_prompt = f"{self.system_prompt}\n\nLog para an√°lise:\n{log_context}"
            
            # Payload para Ollama
            payload = {
                "model": self.model,
                "prompt": full_prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,  # Baixa criatividade para an√°lise t√©cnica
                    "top_p": 0.9,
                    "num_predict": 200   # Limitar tokens para resposta concisa
                }
            }
            
            logger.info(f"ü§ñ Enviando para LLM: {self.model}")
            
            # Fazer requisi√ß√£o
            response = await self.client.post(
                f"{self.ollama_url}/api/generate",
                json=payload
            )
            
            if response.status_code != 200:
                logger.error(f"Ollama API error: {response.status_code}")
                return None
            
            result = response.json()
            llm_response = result.get("response", "").strip()
            
            logger.info(f"üì§ Resposta LLM: {llm_response[:100]}...")
            
            # Parse da resposta JSON
            try:
                analysis = json.loads(llm_response)
                
                # Validar campos obrigat√≥rios
                required_fields = ["resumo", "tipo_ataque", "criticidade", "acao_recomendada"]
                if all(field in analysis for field in required_fields):
                    return analysis
                else:
                    logger.warning("Resposta LLM incompleta, usando fallback")
                    return self._fallback_analysis(log_data)
                    
            except json.JSONDecodeError:
                logger.warning("Resposta LLM n√£o √© JSON v√°lido, usando fallback")
                return self._fallback_analysis(log_data)
                
        except Exception as e:
            logger.error(f"Erro na an√°lise LLM: {str(e)}")
            return self._fallback_analysis(log_data)

    def _prepare_log_context(self, log_data: Dict[Any, Any]) -> str:
        """Preparar contexto estruturado do log"""
        context_parts = []
        
        # Informa√ß√µes b√°sicas
        if "event_type" in log_data:
            context_parts.append(f"Tipo de evento: {log_data['event_type']}")
        
        if "src_ip" in log_data:
            context_parts.append(f"IP origem: {log_data['src_ip']}")
            
        if "dest_ip" in log_data:
            context_parts.append(f"IP destino: {log_data['dest_ip']}")
            
        if "src_port" in log_data:
            context_parts.append(f"Porta origem: {log_data['src_port']}")
            
        if "dest_port" in log_data:
            context_parts.append(f"Porta destino: {log_data['dest_port']}")
            
        if "proto" in log_data:
            context_parts.append(f"Protocolo: {log_data['proto']}")
        
        # Informa√ß√µes espec√≠ficas do alerta
        if "alert" in log_data:
            alert = log_data["alert"]
            if "signature" in alert:
                context_parts.append(f"Assinatura: {alert['signature']}")
            if "category" in alert:
                context_parts.append(f"Categoria: {alert['category']}")
            if "severity" in alert:
                context_parts.append(f"Severidade: {alert['severity']}")
        
        # Payload se dispon√≠vel (limitado)
        if "payload_printable" in log_data:
            payload = log_data["payload_printable"][:200]  # Limitar tamanho
            context_parts.append(f"Payload: {payload}")
        
        return "\n".join(context_parts)

    def _fallback_analysis(self, log_data: Dict[Any, Any]) -> Dict[str, str]:
        """An√°lise de fallback quando LLM falha"""
        event_type = log_data.get("event_type", "unknown")
        src_ip = log_data.get("src_ip", "unknown")
        dest_port = log_data.get("dest_port", "unknown")
        
        # An√°lise b√°sica baseada em regras
        if event_type == "alert":
            alert = log_data.get("alert", {})
            signature = alert.get("signature", "").lower()
            
            if "scan" in signature or "probe" in signature:
                return {
                    "resumo": f"Poss√≠vel port scan detectado de {src_ip}",
                    "tipo_ataque": "port_scan",
                    "criticidade": "m√©dia",
                    "acao_recomendada": "Monitorar IP origem e considerar bloqueio tempor√°rio"
                }
            elif "brute" in signature or "force" in signature:
                return {
                    "resumo": f"Tentativa de for√ßa bruta detectada de {src_ip}",
                    "tipo_ataque": "brute_force",
                    "criticidade": "alta",
                    "acao_recomendada": "Bloquear IP imediatamente e verificar logs de autentica√ß√£o"
                }
            elif "sql" in signature:
                return {
                    "resumo": f"Poss√≠vel SQL injection de {src_ip}",
                    "tipo_ataque": "sql_injection",
                    "criticidade": "alta",
                    "acao_recomendada": "Verificar aplica√ß√£o web e bloquear IP"
                }
        
        # Fallback gen√©rico
        return {
            "resumo": f"Evento de seguran√ßa detectado: {event_type} de {src_ip}",
            "tipo_ataque": event_type,
            "criticidade": "m√©dia",
            "acao_recomendada": "Investigar evento e tomar a√ß√£o conforme pol√≠tica de seguran√ßa"
        }

    async def close(self):
        """Fechar cliente HTTP"""
        await self.client.aclose()